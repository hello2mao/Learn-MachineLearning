{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python375jvsc74a57bd0aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49",
   "display_name": "Python 3.7.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 971,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data1 = pd.read_csv('../../Data/linear-regression-data/data1.csv')\n",
    "data2 = pd.read_csv('../../Data/linear-regression-data/data2.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 972,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.iloc[:10000,:]\n",
    "data2 = data2.iloc[:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['idcard', 'deprice_level', 'tag'], dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 973
    }
   ],
   "source": [
    "data1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 974,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['idcard', 'gjj_status', 'dep_balance_level', 'dep_base_level',\n",
       "       'loan_status', 'pay_base_level', 'insured_status',\n",
       "       'series_pay_year_level', 'last_year_level'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "execution_count": 974
    }
   ],
   "source": [
    "data2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 975,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 975
    }
   ],
   "source": [
    "data1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 976,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 976
    }
   ],
   "source": [
    "data2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 977,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9996"
      ]
     },
     "metadata": {},
     "execution_count": 977
    }
   ],
   "source": [
    "data1.dropna(inplace=True)\n",
    "data1.drop_duplicates(subset=['idcard'])\n",
    "data1.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 978,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "metadata": {},
     "execution_count": 978
    }
   ],
   "source": [
    "data2.drop_duplicates(subset=['idcard'])\n",
    "data2.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 979,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect = pd.merge(data2, data1, on='idcard', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 980,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  idcard  gjj_status  dep_balance_level  dep_base_level  \\\n",
       "9986  11010219880628455X           1                  1               3   \n",
       "9987  110109198511114179           1                  1               2   \n",
       "9988  110105197502107209           1                  1               2   \n",
       "9989  110000195611217603           1                  1               3   \n",
       "9990  110115196105074165           1                  1               3   \n",
       "9991  110100197508117991           1                  1               1   \n",
       "9992  110113197001189912           1                  1               2   \n",
       "9993  110101195609142683           1                  1               3   \n",
       "9994  110104199601044349           1                  1               3   \n",
       "9995  110106197812146728           1                  1               2   \n",
       "\n",
       "      loan_status  pay_base_level  insured_status  series_pay_year_level  \\\n",
       "9986            1               3               1                      2   \n",
       "9987            1               2               1                      2   \n",
       "9988            1               2               1                      2   \n",
       "9989            1               3               1                      2   \n",
       "9990            1               3               1                      2   \n",
       "9991            1               1               1                      1   \n",
       "9992            1               2               1                      2   \n",
       "9993            1               3               1                      1   \n",
       "9994            1               3               1                      1   \n",
       "9995            1               2               1                      2   \n",
       "\n",
       "      last_year_level  deprice_level   tag  \n",
       "9986                2              3  1.96  \n",
       "9987                1              3  1.36  \n",
       "9988                1              2  1.36  \n",
       "9989                2              5  2.16  \n",
       "9990                2              3  1.86  \n",
       "9991                2              5  1.26  \n",
       "9992                1              4  1.56  \n",
       "9993                1              4  1.86  \n",
       "9994                1              3  1.76  \n",
       "9995                1              5  1.66  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>idcard</th>\n      <th>gjj_status</th>\n      <th>dep_balance_level</th>\n      <th>dep_base_level</th>\n      <th>loan_status</th>\n      <th>pay_base_level</th>\n      <th>insured_status</th>\n      <th>series_pay_year_level</th>\n      <th>last_year_level</th>\n      <th>deprice_level</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>9986</th>\n      <td>11010219880628455X</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1.96</td>\n    </tr>\n    <tr>\n      <th>9987</th>\n      <td>110109198511114179</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.36</td>\n    </tr>\n    <tr>\n      <th>9988</th>\n      <td>110105197502107209</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1.36</td>\n    </tr>\n    <tr>\n      <th>9989</th>\n      <td>110000195611217603</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>5</td>\n      <td>2.16</td>\n    </tr>\n    <tr>\n      <th>9990</th>\n      <td>110115196105074165</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1.86</td>\n    </tr>\n    <tr>\n      <th>9991</th>\n      <td>110100197508117991</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>5</td>\n      <td>1.26</td>\n    </tr>\n    <tr>\n      <th>9992</th>\n      <td>110113197001189912</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1.56</td>\n    </tr>\n    <tr>\n      <th>9993</th>\n      <td>110101195609142683</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>4</td>\n      <td>1.86</td>\n    </tr>\n    <tr>\n      <th>9994</th>\n      <td>110104199601044349</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1.76</td>\n    </tr>\n    <tr>\n      <th>9995</th>\n      <td>110106197812146728</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>5</td>\n      <td>1.66</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 980
    }
   ],
   "source": [
    "intersect.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 981,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "9996"
      ]
     },
     "metadata": {},
     "execution_count": 981
    }
   ],
   "source": [
    "intersect.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 982,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nInt64Index: 9996 entries, 0 to 9995\nData columns (total 11 columns):\n #   Column                 Non-Null Count  Dtype  \n---  ------                 --------------  -----  \n 0   idcard                 9996 non-null   object \n 1   gjj_status             9996 non-null   int64  \n 2   dep_balance_level      9996 non-null   int64  \n 3   dep_base_level         9996 non-null   int64  \n 4   loan_status            9996 non-null   int64  \n 5   pay_base_level         9996 non-null   int64  \n 6   insured_status         9996 non-null   int64  \n 7   series_pay_year_level  9996 non-null   int64  \n 8   last_year_level        9996 non-null   int64  \n 9   deprice_level          9996 non-null   int64  \n 10  tag                    9996 non-null   float64\ndtypes: float64(1), int64(9), object(1)\nmemory usage: 937.1+ KB\nNone\n"
     ]
    }
   ],
   "source": [
    "import pprint as pp\n",
    "pp.pprint(intersect.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 983,
   "metadata": {},
   "outputs": [],
   "source": [
    "intersect_corr = intersect.iloc[:, 1:].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 984,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "gjj_status               0.048944\n",
       "dep_balance_level             NaN\n",
       "dep_base_level           0.935970\n",
       "loan_status             -0.052087\n",
       "pay_base_level           0.930297\n",
       "insured_status          -0.052087\n",
       "series_pay_year_level    0.105726\n",
       "last_year_level          0.121406\n",
       "deprice_level            0.268581\n",
       "tag                      1.000000\n",
       "Name: tag, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 984
    }
   ],
   "source": [
    "target_col = intersect_corr['tag']\n",
    "target_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 985,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dep_base_level           0.935970\n",
       "pay_base_level           0.930297\n",
       "series_pay_year_level    0.105726\n",
       "last_year_level          0.121406\n",
       "deprice_level            0.268581\n",
       "tag                      1.000000\n",
       "Name: tag, dtype: float64"
      ]
     },
     "metadata": {},
     "execution_count": 985
    }
   ],
   "source": [
    "feature = target_col[target_col > 0.1]\n",
    "feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 986,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['dep_base_level',\n",
       " 'pay_base_level',\n",
       " 'series_pay_year_level',\n",
       " 'last_year_level',\n",
       " 'deprice_level']"
      ]
     },
     "metadata": {},
     "execution_count": 986
    }
   ],
   "source": [
    "feature_cols = feature.index.tolist()\n",
    "feature_cols.pop()\n",
    "feature_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 987,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[3, 5, 7, 8, 9]"
      ]
     },
     "metadata": {},
     "execution_count": 987
    }
   ],
   "source": [
    "cols = list(intersect.columns) \n",
    "feats_selected = [cols.index(col) for col in feature_cols]  #获取该特征对应列索引编号，后续就可以用feats + feats_selected作为特征值\n",
    "feats_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mode='train'):\n",
    "        self.mode = mode\n",
    "\n",
    "        data = np.array(intersect.iloc[:, feats_selected]).astype(float)\n",
    "        target = np.array(intersect.iloc[:, 10:]).astype(float).squeeze(1)\n",
    "        print('data shape', data.shape)\n",
    "\n",
    "            \n",
    "        # Splitting training data into train & dev sets\n",
    "        indices_tr, indices_dev = train_test_split([i for i in range(data.shape[0])], test_size = 0.3, random_state = 0)\n",
    "        if mode == 'train':\n",
    "            indices = indices_tr\n",
    "        elif mode == 'dev':\n",
    "            indices = indices_dev\n",
    "            \n",
    "        # Convert data into PyTorch tensors\n",
    "        self.data = torch.FloatTensor(data[indices])\n",
    "        self.target = torch.FloatTensor(target[indices])\n",
    "\n",
    "        # Normalize features (you may remove this part to see what will happen)\n",
    "        # eps = 1e-6\n",
    "        self.data[:,:] = \\\n",
    "            (self.data[:,:] - self.data[:,:].mean(dim=0, keepdim=True)) \\\n",
    "            / (self.data[:,:].max(dim=0, keepdim=True) + self.data[:,:].min(dim=0, keepdim=True))\n",
    "\n",
    "        self.dim = self.data.shape[1]\n",
    "\n",
    "        print('Finished reading the {} set of  Dataset ({} samples found, each dim = {})'\n",
    "              .format(mode, len(self.data), self.dim))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Returns one sample at a time\n",
    "        return self.data[index], self.target[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        # Returns the size of the dataset\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.net = nn.Linear(input_dim, 1)\n",
    "        # self.net = nn.Sequential(\n",
    "        #     nn.Linear(input_dim, 64),\n",
    "        #     nn.ReLU(),  \n",
    "        #     nn.Linear(64, 32),\n",
    "        #     nn.ReLU(), \n",
    "        #     nn.Linear(32, 1),\n",
    "        # )\n",
    "\n",
    "        # Mean squared error loss\n",
    "        self.criterion = nn.MSELoss(reduction='mean')\n",
    "\n",
    "    def forward(self, x):\n",
    "        ''' Given input of size (batch_size x input_dim), compute output of the network '''\n",
    "        return self.net(x).squeeze(1)\n",
    "\n",
    "    def cal_loss(self, pred, target):\n",
    "        ''' Calculate loss '''\n",
    "        return self.criterion(pred, target)\n",
    "        # eps = 1e-6\n",
    "        # l2_reg = 0\n",
    "        # alpha = 0.0001\n",
    "        # for name, w in self.linear.named_parameters():\n",
    "        #     if 'weight'  in name:\n",
    "        #         l2_reg += alpha * torch.square(torch.norm(w, p = 2).to(device))\n",
    "        # return torch.sqrt(self.criterion(pred, target)+eps)+l2_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 990,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accu(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    count = 0\n",
    "    samples = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        samples = samples + dv_set.batch_size\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            res = np.abs(pred.numpy()-y.numpy())\n",
    "            c = np.sum(res < 0.01)\n",
    "            count = count + c\n",
    "    return count/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 991,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(tr_set, dv_set, model, config, device):\n",
    "    ''' DNN training '''\n",
    "\n",
    "    n_epochs = config['n_epochs']  # Maximum number of epochs\n",
    "\n",
    "    # Setup optimizer\n",
    "    optimizer = getattr(torch.optim, config['optimizer'])(\n",
    "        model.parameters(), **config['optim_hparas'])\n",
    "\n",
    "    min_mse = 1000.\n",
    "    loss_record = {'train': [], 'dev': []}      # for recording training loss\n",
    "    early_stop_cnt = 0\n",
    "    epoch = 0\n",
    "    while epoch < n_epochs:\n",
    "        model.train()                           # set model to training mode\n",
    "        for x, y in tr_set:                     # iterate through the dataloader\n",
    "            optimizer.zero_grad()               # set gradient to zero\n",
    "            x, y = x.to(device), y.to(device)   # move data to device (cpu/cuda)\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "            mse_loss.backward()                 # compute gradient (backpropagation)\n",
    "            optimizer.step()                    # update model with optimizer\n",
    "            loss_record['train'].append(mse_loss.detach().cpu().item())\n",
    "\n",
    "        # After each epoch, test your model on the validation (development) set.\n",
    "        dev_mse = dev(dv_set, model, device)\n",
    "        if dev_mse < min_mse:\n",
    "            # Save model if your model improved\n",
    "            min_mse = dev_mse\n",
    "            cur_accu = accu(dv_set, model, device)\n",
    "            print('Saving model (epoch = {:4d}, loss = {:.4f}), accu = {:.4f}'\n",
    "                .format(epoch + 1, min_mse, cur_accu))\n",
    "            torch.save(model.state_dict(), config['save_path'])  # Save model to specified path\n",
    "            early_stop_cnt = 0\n",
    "        else:\n",
    "            early_stop_cnt += 1\n",
    "\n",
    "        epoch += 1\n",
    "        loss_record['dev'].append(dev_mse)\n",
    "        if early_stop_cnt > config['early_stop']:\n",
    "            # Stop training if your model stops improving for \"config['early_stop']\" epochs.\n",
    "            break\n",
    "\n",
    "    print('Finished training after {} epochs'.format(epoch))\n",
    "    return min_mse, loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 992,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dev(dv_set, model, device):\n",
    "    model.eval()                                # set model to evalutation mode\n",
    "    total_loss = 0\n",
    "    for x, y in dv_set:                         # iterate through the dataloader\n",
    "        x, y = x.to(device), y.to(device)       # move data to device (cpu/cuda)\n",
    "        with torch.no_grad():                   # disable gradient calculation\n",
    "            pred = model(x)                     # forward pass (compute output)\n",
    "            mse_loss = model.cal_loss(pred, y)  # compute loss\n",
    "        total_loss += mse_loss.detach().cpu().item() * len(x)  # accumulate loss\n",
    "    total_loss = total_loss / len(dv_set.dataset)              # compute averaged loss\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 993,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_device():\n",
    "    ''' Get device (if GPU is available, use GPU) '''\n",
    "    return 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 994,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_dataloader(mode, batch_size, n_jobs=0):\n",
    "    ''' Generates a dataset, then is put into a dataloader. '''\n",
    "    dataset = MyDataset(mode=mode)  # Construct dataset\n",
    "    dataloader = DataLoader(\n",
    "        dataset, batch_size,\n",
    "        shuffle=(mode == 'train'), drop_last=False,\n",
    "        num_workers=n_jobs, pin_memory=True)                            # Construct dataloader\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 966,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "data shape (9996, 5)\nFinished reading the train set of  Dataset (6997 samples found, each dim = 5)\ndata shape (9996, 5)\nFinished reading the dev set of  Dataset (2999 samples found, each dim = 5)\n"
     ]
    }
   ],
   "source": [
    "myseed = 42069  # set a random seed for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(myseed)\n",
    "torch.manual_seed(myseed)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(myseed)\n",
    "\n",
    "device = get_device()                 # get the current available device ('cpu' or 'cuda')\n",
    "os.makedirs('models', exist_ok=True)  # The trained model will be saved to ./models/\n",
    "\n",
    "# TODO: How to tune these hyper-parameters to improve your model's performance?\n",
    "config = {\n",
    "    'n_epochs': 300,                # maximum number of epochs\n",
    "    'batch_size': 1000,               # mini-batch size for dataloader\n",
    "    'optimizer': 'Adam',              # optimization algorithm (optimizer in torch.optim)\n",
    "    'optim_hparas': {                # hyper-parameters for the optimizer (depends on which optimizer you are using)\n",
    "        'lr': 0.001,                 # learning rate of SGD\n",
    "        # 'momentum': 0.9              # momentum for SGD\n",
    "        'betas': [0.9, 0.99]\n",
    "    },\n",
    "    'early_stop': 200,               # early stopping epochs (the number epochs since your model's last improvement)\n",
    "    'save_path': 'models/model.pth'  # your model will be saved here\n",
    "}\n",
    "\n",
    "tr_set = prep_dataloader('train', config['batch_size'])\n",
    "dv_set = prep_dataloader('dev', config['batch_size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 967,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNet(tr_set.dataset.dim).to(device)  # Construct model and move to device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 968,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Saving model (epoch =    1, loss = 1.3998), accu = 0.0000\n",
      "Saving model (epoch =    2, loss = 1.3799), accu = 0.0000\n",
      "Saving model (epoch =    3, loss = 1.3604), accu = 0.0000\n",
      "Saving model (epoch =    4, loss = 1.3413), accu = 0.0000\n",
      "Saving model (epoch =    5, loss = 1.3228), accu = 0.0000\n",
      "Saving model (epoch =    6, loss = 1.3047), accu = 0.0000\n",
      "Saving model (epoch =    7, loss = 1.2869), accu = 0.0000\n",
      "Saving model (epoch =    8, loss = 1.2695), accu = 0.0000\n",
      "Saving model (epoch =    9, loss = 1.2524), accu = 0.0000\n",
      "Saving model (epoch =   10, loss = 1.2356), accu = 0.0000\n",
      "Saving model (epoch =   11, loss = 1.2191), accu = 0.0000\n",
      "Saving model (epoch =   12, loss = 1.2030), accu = 0.0000\n",
      "Saving model (epoch =   13, loss = 1.1870), accu = 0.0000\n",
      "Saving model (epoch =   14, loss = 1.1713), accu = 0.0000\n",
      "Saving model (epoch =   15, loss = 1.1559), accu = 0.0000\n",
      "Saving model (epoch =   16, loss = 1.1407), accu = 0.0000\n",
      "Saving model (epoch =   17, loss = 1.1257), accu = 0.0000\n",
      "Saving model (epoch =   18, loss = 1.1110), accu = 0.0000\n",
      "Saving model (epoch =   19, loss = 1.0963), accu = 0.0000\n",
      "Saving model (epoch =   20, loss = 1.0819), accu = 0.0000\n",
      "Saving model (epoch =   21, loss = 1.0676), accu = 0.0000\n",
      "Saving model (epoch =   22, loss = 1.0535), accu = 0.0000\n",
      "Saving model (epoch =   23, loss = 1.0396), accu = 0.0000\n",
      "Saving model (epoch =   24, loss = 1.0259), accu = 0.0000\n",
      "Saving model (epoch =   25, loss = 1.0122), accu = 0.0000\n",
      "Saving model (epoch =   26, loss = 0.9987), accu = 0.0000\n",
      "Saving model (epoch =   27, loss = 0.9854), accu = 0.0000\n",
      "Saving model (epoch =   28, loss = 0.9722), accu = 0.0000\n",
      "Saving model (epoch =   29, loss = 0.9591), accu = 0.0000\n",
      "Saving model (epoch =   30, loss = 0.9461), accu = 0.0000\n",
      "Saving model (epoch =   31, loss = 0.9333), accu = 0.0000\n",
      "Saving model (epoch =   32, loss = 0.9206), accu = 0.0000\n",
      "Saving model (epoch =   33, loss = 0.9080), accu = 0.0000\n",
      "Saving model (epoch =   34, loss = 0.8955), accu = 0.0000\n",
      "Saving model (epoch =   35, loss = 0.8831), accu = 0.0000\n",
      "Saving model (epoch =   36, loss = 0.8708), accu = 0.0000\n",
      "Saving model (epoch =   37, loss = 0.8587), accu = 0.0000\n",
      "Saving model (epoch =   38, loss = 0.8466), accu = 0.0000\n",
      "Saving model (epoch =   39, loss = 0.8347), accu = 0.0000\n",
      "Saving model (epoch =   40, loss = 0.8228), accu = 0.0000\n",
      "Saving model (epoch =   41, loss = 0.8111), accu = 0.0000\n",
      "Saving model (epoch =   42, loss = 0.7995), accu = 0.0000\n",
      "Saving model (epoch =   43, loss = 0.7879), accu = 0.0000\n",
      "Saving model (epoch =   44, loss = 0.7765), accu = 0.0000\n",
      "Saving model (epoch =   45, loss = 0.7651), accu = 0.0000\n",
      "Saving model (epoch =   46, loss = 0.7539), accu = 0.0000\n",
      "Saving model (epoch =   47, loss = 0.7427), accu = 0.0000\n",
      "Saving model (epoch =   48, loss = 0.7317), accu = 0.0000\n",
      "Saving model (epoch =   49, loss = 0.7207), accu = 0.0000\n",
      "Saving model (epoch =   50, loss = 0.7099), accu = 0.0000\n",
      "Saving model (epoch =   51, loss = 0.6991), accu = 0.0000\n",
      "Saving model (epoch =   52, loss = 0.6884), accu = 0.0000\n",
      "Saving model (epoch =   53, loss = 0.6779), accu = 0.0000\n",
      "Saving model (epoch =   54, loss = 0.6674), accu = 0.0000\n",
      "Saving model (epoch =   55, loss = 0.6570), accu = 0.0000\n",
      "Saving model (epoch =   56, loss = 0.6467), accu = 0.0000\n",
      "Saving model (epoch =   57, loss = 0.6365), accu = 0.0000\n",
      "Saving model (epoch =   58, loss = 0.6264), accu = 0.0000\n",
      "Saving model (epoch =   59, loss = 0.6164), accu = 0.0000\n",
      "Saving model (epoch =   60, loss = 0.6064), accu = 0.0000\n",
      "Saving model (epoch =   61, loss = 0.5966), accu = 0.0000\n",
      "Saving model (epoch =   62, loss = 0.5869), accu = 0.0000\n",
      "Saving model (epoch =   63, loss = 0.5772), accu = 0.0000\n",
      "Saving model (epoch =   64, loss = 0.5677), accu = 0.0000\n",
      "Saving model (epoch =   65, loss = 0.5582), accu = 0.0000\n",
      "Saving model (epoch =   66, loss = 0.5488), accu = 0.0000\n",
      "Saving model (epoch =   67, loss = 0.5395), accu = 0.0000\n",
      "Saving model (epoch =   68, loss = 0.5303), accu = 0.0000\n",
      "Saving model (epoch =   69, loss = 0.5212), accu = 0.0000\n",
      "Saving model (epoch =   70, loss = 0.5122), accu = 0.0000\n",
      "Saving model (epoch =   71, loss = 0.5032), accu = 0.0000\n",
      "Saving model (epoch =   72, loss = 0.4944), accu = 0.0000\n",
      "Saving model (epoch =   73, loss = 0.4856), accu = 0.0000\n",
      "Saving model (epoch =   74, loss = 0.4770), accu = 0.0000\n",
      "Saving model (epoch =   75, loss = 0.4684), accu = 0.0000\n",
      "Saving model (epoch =   76, loss = 0.4599), accu = 0.0000\n",
      "Saving model (epoch =   77, loss = 0.4515), accu = 0.0000\n",
      "Saving model (epoch =   78, loss = 0.4432), accu = 0.0000\n",
      "Saving model (epoch =   79, loss = 0.4349), accu = 0.0000\n",
      "Saving model (epoch =   80, loss = 0.4268), accu = 0.0000\n",
      "Saving model (epoch =   81, loss = 0.4187), accu = 0.0000\n",
      "Saving model (epoch =   82, loss = 0.4107), accu = 0.0000\n",
      "Saving model (epoch =   83, loss = 0.4029), accu = 0.0000\n",
      "Saving model (epoch =   84, loss = 0.3951), accu = 0.0000\n",
      "Saving model (epoch =   85, loss = 0.3873), accu = 0.0000\n",
      "Saving model (epoch =   86, loss = 0.3797), accu = 0.0000\n",
      "Saving model (epoch =   87, loss = 0.3722), accu = 0.0000\n",
      "Saving model (epoch =   88, loss = 0.3647), accu = 0.0003\n",
      "Saving model (epoch =   89, loss = 0.3573), accu = 0.0003\n",
      "Saving model (epoch =   90, loss = 0.3500), accu = 0.0003\n",
      "Saving model (epoch =   91, loss = 0.3428), accu = 0.0007\n",
      "Saving model (epoch =   92, loss = 0.3357), accu = 0.0007\n",
      "Saving model (epoch =   93, loss = 0.3287), accu = 0.0007\n",
      "Saving model (epoch =   94, loss = 0.3217), accu = 0.0000\n",
      "Saving model (epoch =   95, loss = 0.3149), accu = 0.0000\n",
      "Saving model (epoch =   96, loss = 0.3081), accu = 0.0000\n",
      "Saving model (epoch =   97, loss = 0.3014), accu = 0.0000\n",
      "Saving model (epoch =   98, loss = 0.2948), accu = 0.0000\n",
      "Saving model (epoch =   99, loss = 0.2882), accu = 0.0000\n",
      "Saving model (epoch =  100, loss = 0.2818), accu = 0.0000\n",
      "Saving model (epoch =  101, loss = 0.2754), accu = 0.0000\n",
      "Saving model (epoch =  102, loss = 0.2691), accu = 0.0000\n",
      "Saving model (epoch =  103, loss = 0.2629), accu = 0.0000\n",
      "Saving model (epoch =  104, loss = 0.2568), accu = 0.0000\n",
      "Saving model (epoch =  105, loss = 0.2508), accu = 0.0000\n",
      "Saving model (epoch =  106, loss = 0.2448), accu = 0.0000\n",
      "Saving model (epoch =  107, loss = 0.2389), accu = 0.0000\n",
      "Saving model (epoch =  108, loss = 0.2331), accu = 0.0000\n",
      "Saving model (epoch =  109, loss = 0.2274), accu = 0.0000\n",
      "Saving model (epoch =  110, loss = 0.2218), accu = 0.0000\n",
      "Saving model (epoch =  111, loss = 0.2163), accu = 0.0000\n",
      "Saving model (epoch =  112, loss = 0.2108), accu = 0.0000\n",
      "Saving model (epoch =  113, loss = 0.2054), accu = 0.0000\n",
      "Saving model (epoch =  114, loss = 0.2001), accu = 0.0000\n",
      "Saving model (epoch =  115, loss = 0.1949), accu = 0.0000\n",
      "Saving model (epoch =  116, loss = 0.1897), accu = 0.0000\n",
      "Saving model (epoch =  117, loss = 0.1847), accu = 0.0000\n",
      "Saving model (epoch =  118, loss = 0.1797), accu = 0.0000\n",
      "Saving model (epoch =  119, loss = 0.1748), accu = 0.0000\n",
      "Saving model (epoch =  120, loss = 0.1699), accu = 0.0003\n",
      "Saving model (epoch =  121, loss = 0.1652), accu = 0.0007\n",
      "Saving model (epoch =  122, loss = 0.1605), accu = 0.0007\n",
      "Saving model (epoch =  123, loss = 0.1559), accu = 0.0007\n",
      "Saving model (epoch =  124, loss = 0.1514), accu = 0.0007\n",
      "Saving model (epoch =  125, loss = 0.1470), accu = 0.0003\n",
      "Saving model (epoch =  126, loss = 0.1426), accu = 0.0003\n",
      "Saving model (epoch =  127, loss = 0.1383), accu = 0.0000\n",
      "Saving model (epoch =  128, loss = 0.1341), accu = 0.0000\n",
      "Saving model (epoch =  129, loss = 0.1300), accu = 0.0000\n",
      "Saving model (epoch =  130, loss = 0.1259), accu = 0.0000\n",
      "Saving model (epoch =  131, loss = 0.1219), accu = 0.0000\n",
      "Saving model (epoch =  132, loss = 0.1180), accu = 0.0000\n",
      "Saving model (epoch =  133, loss = 0.1142), accu = 0.0000\n",
      "Saving model (epoch =  134, loss = 0.1105), accu = 0.0000\n",
      "Saving model (epoch =  135, loss = 0.1068), accu = 0.0000\n",
      "Saving model (epoch =  136, loss = 0.1032), accu = 0.0000\n",
      "Saving model (epoch =  137, loss = 0.0996), accu = 0.0000\n",
      "Saving model (epoch =  138, loss = 0.0962), accu = 0.0000\n",
      "Saving model (epoch =  139, loss = 0.0928), accu = 0.0000\n",
      "Saving model (epoch =  140, loss = 0.0895), accu = 0.0000\n",
      "Saving model (epoch =  141, loss = 0.0863), accu = 0.0000\n",
      "Saving model (epoch =  142, loss = 0.0831), accu = 0.0000\n",
      "Saving model (epoch =  143, loss = 0.0800), accu = 0.0000\n",
      "Saving model (epoch =  144, loss = 0.0770), accu = 0.0000\n",
      "Saving model (epoch =  145, loss = 0.0740), accu = 0.0000\n",
      "Saving model (epoch =  146, loss = 0.0712), accu = 0.0000\n",
      "Saving model (epoch =  147, loss = 0.0683), accu = 0.0000\n",
      "Saving model (epoch =  148, loss = 0.0656), accu = 0.0000\n",
      "Saving model (epoch =  149, loss = 0.0629), accu = 0.0000\n",
      "Saving model (epoch =  150, loss = 0.0603), accu = 0.0000\n",
      "Saving model (epoch =  151, loss = 0.0578), accu = 0.0000\n",
      "Saving model (epoch =  152, loss = 0.0553), accu = 0.0000\n",
      "Saving model (epoch =  153, loss = 0.0529), accu = 0.0000\n",
      "Saving model (epoch =  154, loss = 0.0506), accu = 0.0000\n",
      "Saving model (epoch =  155, loss = 0.0483), accu = 0.0000\n",
      "Saving model (epoch =  156, loss = 0.0461), accu = 0.0000\n",
      "Saving model (epoch =  157, loss = 0.0440), accu = 0.0000\n",
      "Saving model (epoch =  158, loss = 0.0419), accu = 0.0000\n",
      "Saving model (epoch =  159, loss = 0.0399), accu = 0.0000\n",
      "Saving model (epoch =  160, loss = 0.0380), accu = 0.0003\n",
      "Saving model (epoch =  161, loss = 0.0361), accu = 0.0003\n",
      "Saving model (epoch =  162, loss = 0.0343), accu = 0.0003\n",
      "Saving model (epoch =  163, loss = 0.0325), accu = 0.0003\n",
      "Saving model (epoch =  164, loss = 0.0308), accu = 0.0000\n",
      "Saving model (epoch =  165, loss = 0.0292), accu = 0.0000\n",
      "Saving model (epoch =  166, loss = 0.0276), accu = 0.0000\n",
      "Saving model (epoch =  167, loss = 0.0261), accu = 0.0000\n",
      "Saving model (epoch =  168, loss = 0.0246), accu = 0.0000\n",
      "Saving model (epoch =  169, loss = 0.0232), accu = 0.0000\n",
      "Saving model (epoch =  170, loss = 0.0219), accu = 0.0000\n",
      "Saving model (epoch =  171, loss = 0.0206), accu = 0.0000\n",
      "Saving model (epoch =  172, loss = 0.0194), accu = 0.0000\n",
      "Saving model (epoch =  173, loss = 0.0182), accu = 0.0000\n",
      "Saving model (epoch =  174, loss = 0.0170), accu = 0.0000\n",
      "Saving model (epoch =  175, loss = 0.0160), accu = 0.0000\n",
      "Saving model (epoch =  176, loss = 0.0149), accu = 0.0000\n",
      "Saving model (epoch =  177, loss = 0.0140), accu = 0.0000\n",
      "Saving model (epoch =  178, loss = 0.0130), accu = 0.0007\n",
      "Saving model (epoch =  179, loss = 0.0121), accu = 0.0027\n",
      "Saving model (epoch =  180, loss = 0.0113), accu = 0.0060\n",
      "Saving model (epoch =  181, loss = 0.0105), accu = 0.0250\n",
      "Saving model (epoch =  182, loss = 0.0098), accu = 0.0783\n",
      "Saving model (epoch =  183, loss = 0.0091), accu = 0.0903\n",
      "Saving model (epoch =  184, loss = 0.0084), accu = 0.0880\n",
      "Saving model (epoch =  185, loss = 0.0078), accu = 0.0850\n",
      "Saving model (epoch =  186, loss = 0.0072), accu = 0.0770\n",
      "Saving model (epoch =  187, loss = 0.0067), accu = 0.0237\n",
      "Saving model (epoch =  188, loss = 0.0061), accu = 0.0007\n",
      "Saving model (epoch =  189, loss = 0.0057), accu = 0.0000\n",
      "Saving model (epoch =  190, loss = 0.0052), accu = 0.0000\n",
      "Saving model (epoch =  191, loss = 0.0048), accu = 0.0000\n",
      "Saving model (epoch =  192, loss = 0.0045), accu = 0.0000\n",
      "Saving model (epoch =  193, loss = 0.0041), accu = 0.0000\n",
      "Saving model (epoch =  194, loss = 0.0038), accu = 0.0000\n",
      "Saving model (epoch =  195, loss = 0.0035), accu = 0.0000\n",
      "Saving model (epoch =  196, loss = 0.0033), accu = 0.0000\n",
      "Saving model (epoch =  197, loss = 0.0030), accu = 0.0000\n",
      "Saving model (epoch =  198, loss = 0.0028), accu = 0.0007\n",
      "Saving model (epoch =  199, loss = 0.0027), accu = 0.0027\n",
      "Saving model (epoch =  200, loss = 0.0025), accu = 0.0070\n",
      "Saving model (epoch =  201, loss = 0.0023), accu = 0.0077\n",
      "Saving model (epoch =  202, loss = 0.0022), accu = 0.0130\n",
      "Saving model (epoch =  203, loss = 0.0021), accu = 0.0200\n",
      "Saving model (epoch =  204, loss = 0.0020), accu = 0.0310\n",
      "Saving model (epoch =  205, loss = 0.0019), accu = 0.0393\n",
      "Saving model (epoch =  206, loss = 0.0018), accu = 0.0503\n",
      "Saving model (epoch =  207, loss = 0.0018), accu = 0.1180\n",
      "Saving model (epoch =  208, loss = 0.0017), accu = 0.1603\n",
      "Saving model (epoch =  209, loss = 0.0017), accu = 0.2653\n",
      "Saving model (epoch =  210, loss = 0.0017), accu = 0.3750\n",
      "Saving model (epoch =  211, loss = 0.0016), accu = 0.4563\n",
      "Saving model (epoch =  212, loss = 0.0016), accu = 0.4597\n",
      "Saving model (epoch =  213, loss = 0.0016), accu = 0.4607\n",
      "Saving model (epoch =  214, loss = 0.0016), accu = 0.4633\n",
      "Saving model (epoch =  215, loss = 0.0016), accu = 0.4577\n",
      "Saving model (epoch =  216, loss = 0.0016), accu = 0.4563\n",
      "Saving model (epoch =  217, loss = 0.0016), accu = 0.4583\n",
      "Saving model (epoch =  218, loss = 0.0016), accu = 0.4580\n",
      "Finished training after 300 epochs\n"
     ]
    }
   ],
   "source": [
    "model_loss, model_loss_record = train(tr_set, dv_set, model, config, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 969,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.net.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 970,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.4713333333333333"
      ]
     },
     "metadata": {},
     "execution_count": 970
    }
   ],
   "source": [
    "accu = accu(dv_set, model, device)\n",
    "accu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}